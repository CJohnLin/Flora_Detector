import streamlit as st
import torch
import torchvision.models as models
from torchvision import transforms
from PIL import Image
import os
import random
import numpy as np
import cv2  # ç¢ºä¿ cv2 (OpenCV) æ¨¡çµ„å·²å¼•å…¥
import utils  # ã€ä¿®å¾©é»ä¸€ï¼šæ·»åŠ  utils æ¨¡çµ„å¼•å…¥ã€‘

# --- 1. å¸¸é‡è¨­å®š ---
MODEL_PATH = 'flower_classifier.pth'
CLASS_NAMES_PATH = 'class_names.txt'
TEST_DATA_DIR = './dataset/test'

# ç¢ºä¿æ‰€æœ‰å¿…è¦çš„æª”æ¡ˆéƒ½å­˜åœ¨
if not os.path.exists(MODEL_PATH) or not os.path.exists(CLASS_NAMES_PATH):
    st.error("âŒ æ¨¡å‹æˆ–é¡åˆ¥åç¨±æª”æ¡ˆéºå¤±ï¼è«‹æª¢æŸ¥æ˜¯å¦å·²æˆåŠŸæ¨é€ flower_classifier.pth å’Œ class_names.txtã€‚")
    st.stop()

# --- 2. æ•¸æ“šè¼‰å…¥å’Œåˆå§‹åŒ–ï¼ˆä½¿ç”¨ st.cache_resource è§£æ±ºé‡è¤‡è¼‰å…¥ï¼‰ ---

@st.cache_resource
def load_model():
    """è¼‰å…¥å¾®èª¿å¾Œçš„ ResNet50 æ¨¡å‹ä¸¦è¨­å®šç‚ºè©•ä¼°æ¨¡å¼"""
    # è¼‰å…¥æ¨¡å‹çµæ§‹ï¼Œä½¿ç”¨ IMAGENET1K_V1 æ¬Šé‡ä½œç‚ºèµ·é»
    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
    
    # ä¿®æ”¹æœ€å¾Œä¸€å±¤å…¨é€£æ¥å±¤ä»¥åŒ¹é… 102 å€‹é¡åˆ¥
    num_ftrs = model.fc.in_features
    model.fc = torch.nn.Linear(num_ftrs, 102)

    # è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡ï¼Œå¼·åˆ¶åœ¨ CPU ä¸Šé‹è¡Œ
    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
    except Exception as e:
        st.error(f"âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹æ¬Šé‡: {e}")
        st.stop()

    model.eval()  # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
    return model

@st.cache_resource
def load_class_names():
    """è¼‰å…¥èŠ±å‰é¡åˆ¥åç¨±"""
    with open(CLASS_NAMES_PATH, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f]

# åˆå§‹åŒ–æ¨¡å‹å’Œé¡åˆ¥åç¨±
model_ft = load_model()
class_names = load_class_names()

# åœ–åƒé è™•ç†è½‰æ›
data_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# --- 3. æ ¸å¿ƒé æ¸¬å‡½æ•¸ ---

def predict_image(image_pil):
    """å° PIL åœ–ç‰‡é€²è¡Œé æ¸¬"""
    input_tensor = data_transform(image_pil).unsqueeze(0)
    with torch.no_grad():
        outputs = model_ft(input_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        
        # å–å¾—æœ€é«˜æ©Ÿç‡å’Œé¡åˆ¥ç´¢å¼•
        top_p, top_class_idx = probabilities.topk(1, dim=1)
        
        # è½‰æ›ç‚º Python æ¨™æº–é¡å‹
        predicted_index = top_class_idx.item()
        confidence = top_p.item()
        predicted_name = class_names[predicted_index]
        
        return predicted_name, confidence, predicted_index

# --- 4. éš¨æ©Ÿé¸åœ–å‡½æ•¸ (å¾ ./dataset/test/ ä¸­é¸å–) ---

def get_random_test_image_path(test_data_dir):
    """å¾æ¸¬è©¦é›†ç›®éŒ„ä¸­éš¨æ©Ÿé¸å–ä¸€å¼µåœ–ç‰‡çš„è·¯å¾‘"""
    try:
        all_files = os.listdir(test_data_dir)
        
        # ç¯©é¸å‡ºåœ–ç‰‡æª”æ¡ˆ
        image_files = [f for f in all_files 
                       if os.path.isfile(os.path.join(test_data_dir, f)) and 
                       f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not image_files:
            return None, f"æ¸¬è©¦é›†ç›®éŒ„ '{test_data_dir}' ä¸­æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡æª”æ¡ˆã€‚"
            
        random_image_file = random.choice(image_files)
        full_path = os.path.join(test_data_dir, random_image_file)
        return full_path, None
        
    except Exception as e:
        return None, f"è®€å–æ¸¬è©¦é›†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"

# --- 5. Streamlit UI çµæ§‹ ---

st.title("ğŸŒº æ·±åº¦å­¸ç¿’èŠ±å‰è¾¨è­˜å™¨ (HW5)")

# åˆå§‹åŒ– session state ä¾†å„²å­˜åœ–ç‰‡è·¯å¾‘å’Œç†±åœ–é¡¯ç¤ºç‹€æ…‹
if 'image_path' not in st.session_state:
    st.session_state.image_path = None
if 'show_cam' not in st.session_state:
    st.session_state.show_cam = False

# --- åœ–ç‰‡é¸æ“‡èˆ‡éš¨æ©Ÿé¸åœ– ---
st.header("ğŸ–¼ï¸ é¸æ“‡èŠ±å‰åœ–ç‰‡")

uploaded_file = st.file_uploader("ä¸Šå‚³ä¸€å¼µåœ–ç‰‡", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    st.session_state.image_path = uploaded_file
    st.session_state.show_cam = False # ä¸Šå‚³æ–°åœ–ï¼Œé‡è¨­ CAM ç‹€æ…‹

# å´é‚Šæ¬„æ§åˆ¶
with st.sidebar:
    st.header("ğŸ•¹ï¸ æ‡‰ç”¨ç¨‹å¼æ§åˆ¶")
    
    # éš¨æ©Ÿé¸åœ–æŒ‰éˆ• (ç¢ºä¿ key å”¯ä¸€)
    if st.button("ğŸ² éš¨æ©Ÿé¸å–æ¸¬è©¦åœ–ç‰‡", key="random_btn_final"): 
        random_path, error = get_random_test_image_path(TEST_DATA_DIR)
        
        if error:
            st.error(error)
        else:
            st.session_state.image_path = random_path
            st.session_state.show_cam = False
            st.rerun() 
            
    # CAM é¡¯ç¤ºæ§åˆ¶æŒ‰éˆ• (ç¢ºä¿ key å”¯ä¸€)
    if st.session_state.image_path:
        if st.button("ğŸ”¥ é¡¯ç¤º Grad-CAM ç†±åœ–", key="cam_btn_final"):
            st.session_state.show_cam = not st.session_state.show_cam
            # é€™è£¡ä¸ä½¿ç”¨ rerunï¼Œè®“é‚è¼¯åœ¨ä¸»è…³æœ¬ä¸­åŸ·è¡Œ

# --- 6. åœ–ç‰‡è™•ç†èˆ‡çµæœé¡¯ç¤º ---

current_image = None
if st.session_state.image_path:
    if isinstance(st.session_state.image_path, str):
        # è™•ç†æœ¬åœ°æª”æ¡ˆè·¯å¾‘ (éš¨æ©Ÿé¸åœ–)
        current_image = Image.open(st.session_state.image_path).convert('RGB')
    else:
        # è™•ç† uploaded_file ç‰©ä»¶ (ç”¨æˆ¶ä¸Šå‚³)
        current_image = Image.open(st.session_state.image_path).convert('RGB')

if current_image:
    # é æ¸¬
    predicted_name, confidence, predicted_index = predict_image(current_image)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("åŸå§‹åœ–ç‰‡")
        st.image(current_image, caption="å¾…è¾¨è­˜çš„èŠ±å‰", use_column_width=True)

    with col2:
        st.subheader("é æ¸¬çµæœ")
        st.metric(label="é æ¸¬èŠ±å‰", value=predicted_name)
        st.metric(label="ä¿¡å¿ƒåº¦", value=f"{confidence:.2%}")
        st.markdown(f"---")
        
        # ã€ä¿®å¾©é»äºŒï¼šæ­£ç¢ºèª¿ç”¨ Grad-CAM é‚è¼¯ã€‘
        if st.session_state.show_cam:
            try:
                # èª¿ç”¨ utils.py ä¸­å®šç¾©çš„ generate_grad_cam å‡½æ•¸
                cam_image = utils.generate_grad_cam(
                    model_ft,           # PyTorch æ¨¡å‹
                    current_image,      # åŸå§‹ PIL åœ–ç‰‡
                    predicted_index,    # é æ¸¬çš„é¡åˆ¥ç´¢å¼•
                    data_transform      # åœ–åƒé è™•ç†
                ) 
                
                st.subheader("ğŸ”¥ Grad-CAM ç†±åœ–")
                # é¡¯ç¤ºç”± utils å‡½æ•¸è¿”å›çš„ cam_image
                st.image(cam_image, caption="Grad-CAM è¦–è¦ºåŒ–çµæœ", use_column_width=True) 

            except Exception as e:
                st.error(f"âŒ Grad-CAM é‹ç®—å‡ºéŒ¯: {e}")
                st.exception(e) # é¡¯ç¤ºå®Œæ•´çš„éŒ¯èª¤å †ç–Šè³‡è¨Š
                

else:
    st.info("è«‹åœ¨å·¦å´ä¸Šå‚³åœ–ç‰‡æˆ–é»æ“ŠæŒ‰éˆ•éš¨æ©Ÿé¸å–åœ–ç‰‡é–‹å§‹è¾¨è­˜ã€‚")
