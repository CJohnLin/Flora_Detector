import streamlit as st
import torch
from torchvision import transforms, models
from PIL import Image
import numpy as np
import cv2
import os
import random
import io # ç”¨æ–¼è™•ç†UploadedFileç‰©ä»¶

# --- 1. é…ç½®èˆ‡æ¨¡å‹è·¯å¾‘ ---
MODEL_PATH = 'flower_classifier.pth'
CLASS_NAMES_FILE = 'class_names.txt' 
NUM_CLASSES = 102 # ç¢ºä¿èˆ‡æ‚¨è¨“ç·´æ™‚çš„é¡åˆ¥æ•¸é‡ä¸€è‡´
TARGET_LAYER = 'layer4' # ResNet çš„ç›®æ¨™æ²ç©å±¤
TEST_DATA_DIR = './dataset/test' # æ¸¬è©¦è³‡æ–™é›†è·¯å¾‘


# --- 2. è¼”åŠ©å‡½æ•¸ï¼šæ¨¡å‹è¼‰å…¥èˆ‡åœ–åƒè½‰æ› ---

# åœ–åƒè½‰æ›è¨­å®š (èˆ‡è¨“ç·´æ™‚çš„é©—è­‰é›†è½‰æ›å¿…é ˆä¸€è‡´)
image_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

@st.cache_resource
def load_model(path, num_classes):
    """è¼‰å…¥ PyTorch æ¨¡å‹ (ä½¿ç”¨ ResNet50 çµæ§‹)"""
    try:
        model = models.resnet50(weights=None) 
        num_ftrs = model.fc.in_features
        model.fc = torch.nn.Linear(num_ftrs, num_classes)
        
        # è¼‰å…¥æ¨¡å‹æ¬Šé‡åˆ° CPU
        model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))
        model.eval()
        
        return model
    except FileNotFoundError:
        st.error(f"âŒ æ¨¡å‹æª”æ¡ˆæœªæ‰¾åˆ°: {path}ã€‚è«‹å…ˆåŸ·è¡Œ train_flower_model.pyã€‚")
        st.stop()
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        st.stop()

@st.cache_data
def load_class_names(file_path):
    """è¼‰å…¥èŠ±å‰é¡åˆ¥åç¨±"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f]
    except FileNotFoundError:
        st.error(f"âŒ é¡åˆ¥åç¨±æª”æ¡ˆæœªæ‰¾åˆ°: {file_path}")
        st.stop()

# è¼‰å…¥æ¨¡å‹å’Œé¡åˆ¥åç¨±
model = load_model(MODEL_PATH, NUM_CLASSES)
class_names = load_class_names(CLASS_NAMES_FILE)


# --- 3. æ ¸å¿ƒåŠŸèƒ½ï¼šGrad-CAM å¯¦ä½œ ---

def generate_grad_cam(model, input_image_tensor, target_class_idx, target_layer_name):
    """è¨ˆç®— Grad-CAM ç†±åœ–"""
    feature_map = None
    gradient = None

    # å®šç¾© Hook å‡½æ•¸ä¾†æ“·å–ç‰¹å¾µåœ–å’Œæ¢¯åº¦
    def save_feature_map(module, input, output):
        nonlocal feature_map
        feature_map = output.detach()
    
    def save_gradient(module, grad_input, grad_output):
        nonlocal gradient
        gradient = grad_output[0].detach()

    # æ‰¾åˆ°ç›®æ¨™å±¤
    target_layer = dict(model.named_modules())[target_layer_name]

    # è¨»å†Š hooks
    feature_hook = target_layer.register_forward_hook(save_feature_map)
    gradient_hook = target_layer.register_backward_hook(save_gradient)

    # å‰å‘å‚³æ’­
    output = model(input_image_tensor)
    
    # å¾Œå‘å‚³æ’­ (è¨ˆç®—ç›®æ¨™é¡åˆ¥çš„æ¢¯åº¦)
    model.zero_grad()
    one_hot = torch.zeros(output.shape)
    one_hot[:, target_class_idx] = 1
    output.backward(gradient=one_hot, retain_graph=True)
    
    # ç§»é™¤ hooks
    feature_hook.remove()
    gradient_hook.remove()

    # è¨ˆç®— Grad-CAM æ¬Šé‡ (Alpha)
    pooled_gradients = torch.mean(gradient, dim=[2, 3], keepdim=True) 
    
    # ç”¢ç”Ÿ CAM 
    cam = (feature_map * pooled_gradients).sum(dim=1, keepdim=True) 
    cam = torch.relu(cam)

    # æ­¸ä¸€åŒ– CAM
    cam = cam / (cam.max() + 1e-8) 
    return cam.squeeze().cpu().numpy()

def overlay_heatmap(original_img, cam_mask):
    """å°‡ Grad-CAM ç†±åœ–è¦†è“‹åˆ°åŸå§‹åœ–ç‰‡ä¸Š"""
    img = np.array(original_img.convert("RGB"))
    H, W, _ = img.shape
    
    heatmap = cv2.resize(cam_mask, (W, H))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    
    # çµåˆç†±åœ–å’ŒåŸå§‹åœ–ç‰‡ (Weighted Overlay)
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)
    
    return Image.fromarray(superimposed_img)


# --- 4. éš¨æ©Ÿé¸åœ–å‡½æ•¸ ---

def get_random_test_image_path(test_data_dir):
# ------------------------------------
    """å¾æ¸¬è©¦é›†ç›®éŒ„ä¸­éš¨æ©Ÿé¸å–ä¸€å¼µåœ–ç‰‡çš„è·¯å¾‘ (ç›´æ¥å¾æ ¹ç›®éŒ„æŠ½å–)"""
    try:
        # 1. å–å¾— test è³‡æ–™å¤¾æ ¹ç›®éŒ„ä¸‹çš„æ‰€æœ‰æª”æ¡ˆ
        all_files = os.listdir(test_data_dir)
        
        # 2. éæ¿¾å‡ºæ‰€æœ‰æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ
        image_files = [f for f in all_files 
                       if os.path.isfile(os.path.join(test_data_dir, f)) and 
                       f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not image_files:
            return None, f"æ¸¬è©¦é›†ç›®éŒ„ '{test_data_dir}' ä¸­æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡æª”æ¡ˆã€‚"
            
        # 3. éš¨æ©Ÿé¸æ“‡ä¸€å¼µåœ–ç‰‡
        random_image_file = random.choice(image_files)
        
        # è¿”å›è©²åœ–ç‰‡çš„å®Œæ•´è·¯å¾‘
        full_path = os.path.join(test_data_dir, random_image_file)
        return full_path, None
        
    except Exception as e:
        return None, f"è®€å–æ¸¬è©¦é›†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"

# =========================================================
# === STREAMLIT UI ä¸»é«” ===
# =========================================================

st.set_page_config(page_title="ğŸŒ¸ èŠ±å‰è¾¨è­˜å™¨ (Grad-CAM è§£é‡‹)", layout="wide")

st.title("ğŸŒ¸ Q1 â€” èŠ±å‰è¾¨è­˜å™¨ (Grad-CAM è§£é‡‹)")
st.markdown("ä¸Šå‚³ä¸€å¼µåœ–ç‰‡æˆ–å¾æ¸¬è©¦é›†éš¨æ©Ÿé¸å–ä¸€å¼µï¼Œé€²è¡Œè¾¨è­˜å’Œæ¨¡å‹è§£é‡‹ã€‚")

# åˆå§‹åŒ– Session State ä¾†å„²å­˜ç•¶å‰åœ–ç‰‡ä¾†æº
if 'image_source' not in st.session_state:
    st.session_state['image_source'] = None
    st.session_state['is_random'] = False

st.header("Upload or Select Image")

# --- éš¨æ©Ÿé¸åœ–æŒ‰éˆ• ---
col_rand, col_upload = st.columns([1, 2])

with col_rand:
    if st.button("ğŸ² éš¨æ©Ÿé¸å–æ¸¬è©¦åœ–ç‰‡", use_container_width=True, help=f"å¾ {TEST_DATA_DIR} éš¨æ©Ÿè¼‰å…¥"):
        random_path, error = get_random_test_image_path(TEST_DATA_DIR)
        if error:
            st.error(error)
        elif random_path:
            st.session_state['image_source'] = random_path
            st.session_state['is_random'] = True
            st.toast(f"å·²å¾æ¸¬è©¦é›†éš¨æ©Ÿé¸å–åœ–ç‰‡ã€‚", icon='âœ…')

# --- åœ–ç‰‡ä¸Šå‚³ ---
with col_upload:
    uploaded_file = st.file_uploader("æˆ–ä¸Šå‚³æ‚¨è‡ªå·±çš„åœ–ç‰‡...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # å¦‚æœä½¿ç”¨è€…ä¸Šå‚³äº†æ–°æª”æ¡ˆï¼Œå‰‡æ›´æ–°ç‹€æ…‹
    st.session_state['image_source'] = uploaded_file
    st.session_state['is_random'] = False


# --- è™•ç†å’Œé¡¯ç¤ºåœ–ç‰‡ ---
image_to_process = None

if st.session_state['image_source']:
    source = st.session_state['image_source']
    
    if isinstance(source, str): # éš¨æ©Ÿé¸åœ– (è·¯å¾‘)
        image_to_process = Image.open(source)
        caption_text = f"éš¨æ©Ÿæ¸¬è©¦åœ–ç‰‡ (æª”æ¡ˆ: {os.path.basename(source)})"
            
    else: # ä¸Šå‚³æª”æ¡ˆ (UploadedFile ç‰©ä»¶)
        image_to_process = Image.open(io.BytesIO(source.read())) # å¾ BytesIO è®€å–
        caption_text = f'ä½¿ç”¨è€…ä¸Šå‚³çš„åœ–ç‰‡ ({source.name})'
        source.seek(0) # é‡ç½®æª”æ¡ˆæŒ‡æ¨™ï¼Œé˜²æ­¢é‡è¤‡è®€å–

# --- é¡¯ç¤ºçµæœå€å¡Š ---

if image_to_process is not None:
    
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1.5])
    
    with col1:
        st.subheader("ğŸ–¼ï¸ åŸå§‹åœ–ç‰‡")
        st.image(image_to_process, caption=caption_text, use_column_width=True)
        
    with col2:
        st.subheader("ğŸ’¡ è¾¨è­˜èˆ‡è§£é‡‹çµæœ")
        
        # é€²è¡Œé æ¸¬
        input_tensor = image_transforms(image_to_process).unsqueeze(0) 
        
        with torch.no_grad():
            output = model(input_tensor)
        
        probabilities = torch.nn.functional.softmax(output, dim=1).squeeze()
        confidence, predicted_idx = torch.max(probabilities, 0)
        
        predicted_class = class_names[predicted_idx.item()]
        confidence_perc = f"{confidence.item() * 100:.2f}%"

        st.success(f"**é æ¸¬èŠ±å‰:** {predicted_class}")
        st.info(f"**ä¿¡å¿ƒå€¼:** {confidence_perc}")

        st.markdown("---")
        
        # --- Grad-CAM è¨ˆç®—èˆ‡é¡¯ç¤ºæŒ‰éˆ• ---
        if st.button("ğŸ”¥ é¡¯ç¤º Grad-CAM ç†±åœ–", type="primary"):
            with st.spinner('è¨ˆç®— Grad-CAM ç†±åœ–ä¸­...'):
                try:
                    # Grad-CAM è¨ˆç®—
                    # å¿…é ˆé‡æ–°é‹è¡Œ image_transformsï¼Œå› ç‚ºå¼µé‡åœ¨ä¹‹å‰å·²ç¶“ä½¿ç”¨é (ä¸èƒ½ retain_graph=True)
                    cam_mask = generate_grad_cam(
                        model, 
                        image_transforms(image_to_process).unsqueeze(0),
                        predicted_idx.item(), 
                        TARGET_LAYER
                    )
                    
                    heatmap_image = overlay_heatmap(image_to_process, cam_mask)
                    
                    st.subheader("ğŸ”¥ Grad-CAM ç†±åœ–è§£é‡‹")
                    st.image(heatmap_image, caption="æ¨¡å‹é—œæ³¨å€åŸŸ (ç†±åœ–è¶Šç´…è¡¨ç¤ºè¶Šé‡è¦)", use_column_width=True)
                    st.caption(f"Grad-CAM ä½¿ç”¨çš„æ¨¡å‹å±¤: `{TARGET_LAYER}`")
                    
                except Exception as e:
                    st.error(f"Grad-CAM è¨ˆç®—å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¨¡å‹å’Œ PyTorch ç‰ˆæœ¬æ˜¯å¦å…¼å®¹: {e}")

# --- HW5 å…±åŒè¦æ±‚æé†’ ---
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“‹ HW5 å…±åŒè¦æ±‚")
st.sidebar.success("1. ChatGPT / AI Agent å°è©±éç¨‹ (å¿…è¦)")
st.sidebar.success("2. GitHub Repository (å¿…è¦)")
st.sidebar.success("3. Streamlit.app Demo é€£çµ (å¿…è¦)")

import streamlit as st
import torch
from torchvision import transforms, models
from PIL import Image
import numpy as np
import cv2
import os
import random
import io # ç”¨æ–¼è™•ç†UploadedFileç‰©ä»¶

# --- 1. é…ç½®èˆ‡æ¨¡å‹è·¯å¾‘ ---
MODEL_PATH = 'flower_classifier.pth'
CLASS_NAMES_FILE = 'class_names.txt' 
NUM_CLASSES = 102 # ç¢ºä¿èˆ‡æ‚¨è¨“ç·´æ™‚çš„é¡åˆ¥æ•¸é‡ä¸€è‡´
TARGET_LAYER = 'layer4' # ResNet çš„ç›®æ¨™æ²ç©å±¤
TEST_DATA_DIR = './dataset/test' # æ¸¬è©¦è³‡æ–™é›†è·¯å¾‘


# --- 2. è¼”åŠ©å‡½æ•¸ï¼šæ¨¡å‹è¼‰å…¥èˆ‡åœ–åƒè½‰æ› ---

# åœ–åƒè½‰æ›è¨­å®š (èˆ‡è¨“ç·´æ™‚çš„é©—è­‰é›†è½‰æ›å¿…é ˆä¸€è‡´)
image_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

@st.cache_resource
def load_model(path, num_classes):
    """è¼‰å…¥ PyTorch æ¨¡å‹ (ä½¿ç”¨ ResNet50 çµæ§‹)"""
    try:
        model = models.resnet50(weights=None) 
        num_ftrs = model.fc.in_features
        model.fc = torch.nn.Linear(num_ftrs, num_classes)
        
        # è¼‰å…¥æ¨¡å‹æ¬Šé‡åˆ° CPU
        model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))
        model.eval()
        
        return model
    except FileNotFoundError:
        st.error(f"âŒ æ¨¡å‹æª”æ¡ˆæœªæ‰¾åˆ°: {path}ã€‚è«‹å…ˆåŸ·è¡Œ train_flower_model.pyã€‚")
        st.stop()
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        st.stop()

@st.cache_data
def load_class_names(file_path):
    """è¼‰å…¥èŠ±å‰é¡åˆ¥åç¨±"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f]
    except FileNotFoundError:
        st.error(f"âŒ é¡åˆ¥åç¨±æª”æ¡ˆæœªæ‰¾åˆ°: {file_path}")
        st.stop()

# è¼‰å…¥æ¨¡å‹å’Œé¡åˆ¥åç¨±
model = load_model(MODEL_PATH, NUM_CLASSES)
class_names = load_class_names(CLASS_NAMES_FILE)


# --- 3. æ ¸å¿ƒåŠŸèƒ½ï¼šGrad-CAM å¯¦ä½œ ---

def generate_grad_cam(model, input_image_tensor, target_class_idx, target_layer_name):
    """è¨ˆç®— Grad-CAM ç†±åœ–"""
    feature_map = None
    gradient = None

    # å®šç¾© Hook å‡½æ•¸ä¾†æ“·å–ç‰¹å¾µåœ–å’Œæ¢¯åº¦
    def save_feature_map(module, input, output):
        nonlocal feature_map
        feature_map = output.detach()
    
    def save_gradient(module, grad_input, grad_output):
        nonlocal gradient
        gradient = grad_output[0].detach()

    # æ‰¾åˆ°ç›®æ¨™å±¤
    target_layer = dict(model.named_modules())[target_layer_name]

    # è¨»å†Š hooks
    feature_hook = target_layer.register_forward_hook(save_feature_map)
    gradient_hook = target_layer.register_backward_hook(save_gradient)

    # å‰å‘å‚³æ’­
    output = model(input_image_tensor)
    
    # å¾Œå‘å‚³æ’­ (è¨ˆç®—ç›®æ¨™é¡åˆ¥çš„æ¢¯åº¦)
    model.zero_grad()
    one_hot = torch.zeros(output.shape)
    one_hot[:, target_class_idx] = 1
    output.backward(gradient=one_hot, retain_graph=True)
    
    # ç§»é™¤ hooks
    feature_hook.remove()
    gradient_hook.remove()

    # è¨ˆç®— Grad-CAM æ¬Šé‡ (Alpha)
    pooled_gradients = torch.mean(gradient, dim=[2, 3], keepdim=True) 
    
    # ç”¢ç”Ÿ CAM 
    cam = (feature_map * pooled_gradients).sum(dim=1, keepdim=True) 
    cam = torch.relu(cam)

    # æ­¸ä¸€åŒ– CAM
    cam = cam / (cam.max() + 1e-8) 
    return cam.squeeze().cpu().numpy()

def overlay_heatmap(original_img, cam_mask):
    """å°‡ Grad-CAM ç†±åœ–è¦†è“‹åˆ°åŸå§‹åœ–ç‰‡ä¸Š"""
    img = np.array(original_img.convert("RGB"))
    H, W, _ = img.shape
    
    heatmap = cv2.resize(cam_mask, (W, H))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    
    # çµåˆç†±åœ–å’ŒåŸå§‹åœ–ç‰‡ (Weighted Overlay)
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)
    
    return Image.fromarray(superimposed_img)


# --- 4. éš¨æ©Ÿé¸åœ–å‡½æ•¸ ---

def get_random_test_image_path(test_data_dir):
# ------------------------------------
    """å¾æ¸¬è©¦é›†ç›®éŒ„ä¸­éš¨æ©Ÿé¸å–ä¸€å¼µåœ–ç‰‡çš„è·¯å¾‘ (ç›´æ¥å¾æ ¹ç›®éŒ„æŠ½å–)"""
    try:
        # 1. å–å¾— test è³‡æ–™å¤¾æ ¹ç›®éŒ„ä¸‹çš„æ‰€æœ‰æª”æ¡ˆ
        all_files = os.listdir(test_data_dir)
        
        # 2. éæ¿¾å‡ºæ‰€æœ‰æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ
        image_files = [f for f in all_files 
                       if os.path.isfile(os.path.join(test_data_dir, f)) and 
                       f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not image_files:
            return None, f"æ¸¬è©¦é›†ç›®éŒ„ '{test_data_dir}' ä¸­æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡æª”æ¡ˆã€‚"
            
        # 3. éš¨æ©Ÿé¸æ“‡ä¸€å¼µåœ–ç‰‡
        random_image_file = random.choice(image_files)
        
        # è¿”å›è©²åœ–ç‰‡çš„å®Œæ•´è·¯å¾‘
        full_path = os.path.join(test_data_dir, random_image_file)
        return full_path, None
        
    except Exception as e:
        return None, f"è®€å–æ¸¬è©¦é›†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"

# =========================================================
# === STREAMLIT UI ä¸»é«” ===
# =========================================================

st.set_page_config(page_title="ğŸŒ¸ èŠ±å‰è¾¨è­˜å™¨ (Grad-CAM è§£é‡‹)", layout="wide")

st.title("ğŸŒ¸ Q1 â€” èŠ±å‰è¾¨è­˜å™¨ (Grad-CAM è§£é‡‹)")
st.markdown("ä¸Šå‚³ä¸€å¼µåœ–ç‰‡æˆ–å¾æ¸¬è©¦é›†éš¨æ©Ÿé¸å–ä¸€å¼µï¼Œé€²è¡Œè¾¨è­˜å’Œæ¨¡å‹è§£é‡‹ã€‚")

# åˆå§‹åŒ– Session State ä¾†å„²å­˜ç•¶å‰åœ–ç‰‡ä¾†æº
if 'image_source' not in st.session_state:
    st.session_state['image_source'] = None
    st.session_state['is_random'] = False

st.header("Upload or Select Image")

# --- éš¨æ©Ÿé¸åœ–æŒ‰éˆ• ---
col_rand, col_upload = st.columns([1, 2])

with col_rand:
    if st.button("ğŸ² éš¨æ©Ÿé¸å–æ¸¬è©¦åœ–ç‰‡", use_container_width=True, help=f"å¾ {TEST_DATA_DIR} éš¨æ©Ÿè¼‰å…¥"):
        random_path, error = get_random_test_image_path(TEST_DATA_DIR)
        if error:
            st.error(error)
        elif random_path:
            st.session_state['image_source'] = random_path
            st.session_state['is_random'] = True
            st.toast(f"å·²å¾æ¸¬è©¦é›†éš¨æ©Ÿé¸å–åœ–ç‰‡ã€‚", icon='âœ…')

# --- åœ–ç‰‡ä¸Šå‚³ ---
with col_upload:
    uploaded_file = st.file_uploader("æˆ–ä¸Šå‚³æ‚¨è‡ªå·±çš„åœ–ç‰‡...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # å¦‚æœä½¿ç”¨è€…ä¸Šå‚³äº†æ–°æª”æ¡ˆï¼Œå‰‡æ›´æ–°ç‹€æ…‹
    st.session_state['image_source'] = uploaded_file
    st.session_state['is_random'] = False


# --- è™•ç†å’Œé¡¯ç¤ºåœ–ç‰‡ ---
image_to_process = None

if st.session_state['image_source']:
    source = st.session_state['image_source']
    
    if isinstance(source, str): # éš¨æ©Ÿé¸åœ– (è·¯å¾‘)
        image_to_process = Image.open(source)
        caption_text = f"éš¨æ©Ÿæ¸¬è©¦åœ–ç‰‡ (æª”æ¡ˆ: {os.path.basename(source)})"
            
    else: # ä¸Šå‚³æª”æ¡ˆ (UploadedFile ç‰©ä»¶)
        image_to_process = Image.open(io.BytesIO(source.read())) # å¾ BytesIO è®€å–
        caption_text = f'ä½¿ç”¨è€…ä¸Šå‚³çš„åœ–ç‰‡ ({source.name})'
        source.seek(0) # é‡ç½®æª”æ¡ˆæŒ‡æ¨™ï¼Œé˜²æ­¢é‡è¤‡è®€å–

# --- é¡¯ç¤ºçµæœå€å¡Š ---

if image_to_process is not None:
    
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1.5])
    
    with col1:
        st.subheader("ğŸ–¼ï¸ åŸå§‹åœ–ç‰‡")
        st.image(image_to_process, caption=caption_text, use_column_width=True)
        
    with col2:
        st.subheader("ğŸ’¡ è¾¨è­˜èˆ‡è§£é‡‹çµæœ")
        
        # é€²è¡Œé æ¸¬
        input_tensor = image_transforms(image_to_process).unsqueeze(0) 
        
        with torch.no_grad():
            output = model(input_tensor)
        
        probabilities = torch.nn.functional.softmax(output, dim=1).squeeze()
        confidence, predicted_idx = torch.max(probabilities, 0)
        
        predicted_class = class_names[predicted_idx.item()]
        confidence_perc = f"{confidence.item() * 100:.2f}%"

        st.success(f"**é æ¸¬èŠ±å‰:** {predicted_class}")
        st.info(f"**ä¿¡å¿ƒå€¼:** {confidence_perc}")

        st.markdown("---")
        
        # --- Grad-CAM è¨ˆç®—èˆ‡é¡¯ç¤ºæŒ‰éˆ• ---
        if st.button("ğŸ”¥ é¡¯ç¤º Grad-CAM ç†±åœ–", type="primary"):
            with st.spinner('è¨ˆç®— Grad-CAM ç†±åœ–ä¸­...'):
                try:
                    # Grad-CAM è¨ˆç®—
                    # å¿…é ˆé‡æ–°é‹è¡Œ image_transformsï¼Œå› ç‚ºå¼µé‡åœ¨ä¹‹å‰å·²ç¶“ä½¿ç”¨é (ä¸èƒ½ retain_graph=True)
                    cam_mask = generate_grad_cam(
                        model, 
                        image_transforms(image_to_process).unsqueeze(0),
                        predicted_idx.item(), 
                        TARGET_LAYER
                    )
                    
                    heatmap_image = overlay_heatmap(image_to_process, cam_mask)
                    
                    st.subheader("ğŸ”¥ Grad-CAM ç†±åœ–è§£é‡‹")
                    st.image(heatmap_image, caption="æ¨¡å‹é—œæ³¨å€åŸŸ (ç†±åœ–è¶Šç´…è¡¨ç¤ºè¶Šé‡è¦)", use_column_width=True)
                    st.caption(f"Grad-CAM ä½¿ç”¨çš„æ¨¡å‹å±¤: `{TARGET_LAYER}`")
                    
                except Exception as e:
                    st.error(f"Grad-CAM è¨ˆç®—å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¨¡å‹å’Œ PyTorch ç‰ˆæœ¬æ˜¯å¦å…¼å®¹: {e}")

# --- HW5 å…±åŒè¦æ±‚æé†’ ---
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“‹ HW5 å…±åŒè¦æ±‚")
st.sidebar.success("1. ChatGPT / AI Agent å°è©±éç¨‹ (å¿…è¦)")
st.sidebar.success("2. GitHub Repository (å¿…è¦)")
st.sidebar.success("3. Streamlit.app Demo é€£çµ (å¿…è¦)")
st.sidebar.markdown("è«‹å°‡æ‰€æœ‰æª”æ¡ˆæ¨é€åˆ° GitHubï¼Œä¸¦éƒ¨ç½² Streamlitã€‚")